{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Implementation and Experiments\n",
    "\n",
    "This notebook demonstrates the RNN implementation and experiments. We'll work with the NusaX-Sentiment dataset to perform text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dropout, Dense, Bidirectional\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.src.models.base_model.utils.nusax_loader import NusaXLoader\n",
    "from src.models.src.models.rnn.experiment import RNNExperiments\n",
    "from src.models.src.models.rnn.rnn_model import RNNModel\n",
    "from src.models.src.models.rnn.rnn_layer import RNNLayer\n",
    "from src.models.src.models.base_model.layers.embedding_layer import EmbeddingLayer\n",
    "from src.models.src.models.base_model.layers.dense_layer import DenseLayer\n",
    "from src.models.src.models.base_model.layers.dropout_layer import DropoutLayer\n",
    "from src.models.src.models.base_model.layers.activation_layer import Softmax\n",
    "from src.models.src.models.base_model.utils.evaluation import compare_keras_vs_scratch\n",
    "from src.models.src.models.base_model.utils.visualization import plot_training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"Num GPUs Available: {len(gpus)}\")\n",
    "        print(f\"Num Logical GPUs: {len(logical_gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init data loader\n",
    "data_loader = NusaXLoader(batch_size=32, add=True)\n",
    "# Ini add buat ngubah pathnya nambah \"../\" tapi harusnya gaperlu soalnya di file siblingnsnya juga gapake ini, api entah kenapa gabisa jalan kalo gadipasang\n",
    "\n",
    "# Train\n",
    "train_dataset = data_loader.get_dataset('train')\n",
    "for tokens, labels in train_dataset.take(1):\n",
    "    sample_tokens = tokens.numpy()\n",
    "    sample_labels = labels.numpy()\n",
    "    break\n",
    "\n",
    "# Get vocabulary\n",
    "vocab = data_loader.get_vocabulary()\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(f\"First 20 words in vocabulary: {vocab[:20]}\")\n",
    "\n",
    "# Output Example\n",
    "print(\"\\nSample texts:\")\n",
    "for i in range(3):\n",
    "    # Convert token IDs back to words\n",
    "    words = [vocab[idx] if idx < len(vocab) else \"[UNK]\" for idx in sample_tokens[i] if idx > 0]\n",
    "    text = \" \".join(words)\n",
    "    print(f\"Text {i+1}: {text}\")\n",
    "    print(f\"Label: {sample_labels[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Experiments with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = RNNExperiments(data_loader=data_loader, batch_size=32, epochs=10, embedding_dim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Experiment: Number of RNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_count_variants = [\n",
    "    (1, \"1 RNN Layer\"),\n",
    "    (2, \"2 RNN Layers\"),\n",
    "    (3, \"3 RNN Layers\")\n",
    "]\n",
    "\n",
    "# Run experiment\n",
    "layer_count_models, layer_count_histories = experiments.run_layer_count_experiment(layer_count_variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Experiment: Number of RNN Cells per Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variants for cell counts\n",
    "cell_count_variants = [\n",
    "    ([32], \"32 Units\"),\n",
    "    ([64], \"64 Units\"),\n",
    "    ([128], \"128 Units\")\n",
    "]\n",
    "\n",
    "# Run experiment\n",
    "cell_count_models, cell_count_histories = experiments.run_cell_count_experiment(cell_count_variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Experiment: RNN Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variants for RNN direction\n",
    "direction_variants = [\n",
    "    (False, \"Unidirectional RNN\"),\n",
    "    (True, \"Bidirectional RNN\")\n",
    "]\n",
    "\n",
    "# Run experiment\n",
    "direction_models, direction_histories = experiments.run_direction_experiment(direction_variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. From-Scratch RNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_path = \"../output/models/rnn/rnn_cells_32.keras\"\n",
    "print(experiments.compare_models(keras_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_path = \"../output/models/rnn/rnn_layers_3.keras\"\n",
    "print(experiments.compare_models(keras_model_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
