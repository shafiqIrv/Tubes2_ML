{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN From Scratch Testing\n",
    "\n",
    "This notebook tests the from-scratch RNN implementation against trained Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 07:53:46.715606: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748566426.739830   10943 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748566426.747065   10943 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748566426.767174   10943 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748566426.767235   10943 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748566426.767238   10943 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748566426.767240   10943 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-30 07:53:46.773758: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "sys.path.append('../../../')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We'll load the NusaX dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748566431.353528   10943 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3248 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2836\n",
      "Number of classes: 3\n",
      "Maximum sequence length: 100\n"
     ]
    }
   ],
   "source": [
    "from src.models.src.models.base_model.utils.nusax_loader import NusaXLoader\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = NusaXLoader(\n",
    "    batch_size=32,\n",
    "    max_sequence_length=100,\n",
    "    vocab_size=10000,\n",
    "    add = True\n",
    ")\n",
    "\n",
    "# Load datasets and initialize vocabulary \n",
    "train_dataset = data_loader.get_dataset(\"train\")  # This initializes the vocabulary\n",
    "val_dataset = data_loader.get_dataset(\"valid\")\n",
    "test_dataset = data_loader.get_dataset(\"test\")\n",
    "\n",
    "# Get raw test data for evaluation\n",
    "x_test, y_test = data_loader.get_vectorized_data(\"test\")\n",
    "\n",
    "# Now we can get the dataset characteristics\n",
    "vocab_size = len(data_loader.get_vocabulary())\n",
    "num_classes = data_loader.num_classes\n",
    "max_sequence_length = data_loader.max_sequence_length\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Maximum sequence length: {max_sequence_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Trained Keras Models\n",
    "\n",
    "We'll load the trained Keras models from our previous experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 32_units_rnn not found at ../../output/models/rnn/32_units_rnn.keras\n",
      "Model 64_units_rnn not found at ../../output/models/rnn/64_units_rnn.keras\n",
      "Model 128_units_rnn not found at ../../output/models/rnn/128_units_rnn.keras\n",
      "Model unidirectional_rnn not found at ../../output/models/rnn/unidirectional_rnn.keras\n",
      "Model bidirectional_rnn not found at ../../output/models/rnn/bidirectional_rnn.keras\n",
      "\n",
      "Layer_count models:\n",
      "  1_layer: Loaded successfully\n",
      "  2_layer: Loaded successfully\n",
      "  3_layer: Loaded successfully\n",
      "\n",
      "Cell_count models:\n",
      "  32_units: Not found\n",
      "  64_units: Not found\n",
      "  128_units: Not found\n",
      "\n",
      "Direction models:\n",
      "  unidirectional: Not found\n",
      "  bidirectional: Not found\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "# Function to load a Keras model if it exists\n",
    "def load_keras_model(model_name):\n",
    "    model_path = f\"../../output/models/rnn/{model_name}.keras\"\n",
    "    if os.path.exists(model_path):\n",
    "        return load_model(model_path)\n",
    "    else:\n",
    "        print(f\"Model {model_name} not found at {model_path}\")\n",
    "        return None\n",
    "\n",
    "# Load models from each experiment\n",
    "keras_models = {\n",
    "    \"layer_count\": {\n",
    "        \"1_layer\": load_keras_model(\"1_layer_rnn\"),\n",
    "        \"2_layer\": load_keras_model(\"2_layer_rnn\"),\n",
    "        \"3_layer\": load_keras_model(\"3_layer_rnn\")\n",
    "    },\n",
    "    \"cell_count\": {\n",
    "        \"32_units\": load_keras_model(\"32_units_rnn\"),\n",
    "        \"64_units\": load_keras_model(\"64_units_rnn\"),\n",
    "        \"128_units\": load_keras_model(\"128_units_rnn\")\n",
    "    },\n",
    "    \"direction\": {\n",
    "        \"unidirectional\": load_keras_model(\"unidirectional_rnn\"),\n",
    "        \"bidirectional\": load_keras_model(\"bidirectional_rnn\")\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check which models were successfully loaded\n",
    "for exp_type, models in keras_models.items():\n",
    "    print(f\"\\n{exp_type.capitalize()} models:\")\n",
    "    for name, model in models.items():\n",
    "        if model is not None:\n",
    "            print(f\"  {name}: Loaded successfully\")\n",
    "        else:\n",
    "            print(f\"  {name}: Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From-Scratch RNN Implementation\n",
    "\n",
    "Now we'll build from-scratch RNN models that match the Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building from-scratch model for 1_layer...\n",
      "Error loading weights for 1_layer: Layer count mismatch: Custom model has 5 layers, Keras model has 4 layers\n",
      "Building from-scratch model for 2_layer...\n",
      "Error loading weights for 2_layer: Layer count mismatch: Custom model has 7 layers, Keras model has 6 layers\n",
      "Building from-scratch model for 3_layer...\n",
      "Error loading weights for 3_layer: Layer count mismatch: Custom model has 9 layers, Keras model has 8 layers\n"
     ]
    }
   ],
   "source": [
    "from src.models.src.models.rnn.rnn_model import RNNModel\n",
    "from src.models.src.models.rnn.rnn_layer import RNNLayer\n",
    "from src.models.src.models.base_model.layers.embedding_layer import EmbeddingLayer\n",
    "from src.models.src.models.base_model.layers.dense_layer import DenseLayer\n",
    "from src.models.src.models.base_model.layers.dropout_layer import DropoutLayer\n",
    "from src.models.src.models.base_model.layers.activation_layer import Softmax\n",
    "\n",
    "def build_scratch_model(keras_model, model_name):\n",
    "    \"\"\"Build a from-scratch model that matches the given Keras model\"\"\"\n",
    "    if keras_model is None:\n",
    "        return None\n",
    "    \n",
    "    scratch_model = RNNModel()\n",
    "    \n",
    "    # Extract architecture information from the model name\n",
    "    is_bidirectional = \"bidirectional\" in model_name\n",
    "    \n",
    "    # Default settings\n",
    "    rnn_units = 128\n",
    "    embedding_dim = 100\n",
    "    num_layers = 1\n",
    "    \n",
    "    # Override settings based on model name\n",
    "    if \"32_units\" in model_name:\n",
    "        rnn_units = 32\n",
    "    elif \"64_units\" in model_name:\n",
    "        rnn_units = 64\n",
    "        \n",
    "    if \"2_layer\" in model_name:\n",
    "        num_layers = 2\n",
    "    elif \"3_layer\" in model_name:\n",
    "        num_layers = 3\n",
    "    \n",
    "    # Add embedding layer\n",
    "    scratch_model.add(EmbeddingLayer(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "    \n",
    "    # Add RNN layers\n",
    "    if num_layers == 1:\n",
    "        # Single RNN layer\n",
    "        scratch_model.add(RNNLayer(input_dim=embedding_dim, hidden_dim=rnn_units, bidirectional=is_bidirectional))\n",
    "        scratch_model.add(DropoutLayer(dropout_rate=0.2))\n",
    "        \n",
    "        # For dense layer, input dim depends on whether RNN is bidirectional\n",
    "        dense_input_dim = rnn_units * 2 if is_bidirectional else rnn_units\n",
    "        \n",
    "    elif num_layers == 2:\n",
    "        # First RNN layer (returns sequences for next RNN layer)\n",
    "        scratch_model.add(RNNLayer(input_dim=embedding_dim, hidden_dim=rnn_units, bidirectional=is_bidirectional))\n",
    "        scratch_model.add(DropoutLayer(dropout_rate=0.2))\n",
    "        \n",
    "        # Second RNN layer\n",
    "        second_layer_input_dim = rnn_units * 2 if is_bidirectional else rnn_units\n",
    "        second_layer_units = rnn_units // 2  # Assuming second layer has half the units\n",
    "        scratch_model.add(RNNLayer(input_dim=second_layer_input_dim, hidden_dim=second_layer_units, bidirectional=is_bidirectional))\n",
    "        scratch_model.add(DropoutLayer(dropout_rate=0.2))\n",
    "        \n",
    "        # For dense layer\n",
    "        dense_input_dim = second_layer_units * 2 if is_bidirectional else second_layer_units\n",
    "        \n",
    "    elif num_layers == 3:\n",
    "        # First RNN layer\n",
    "        scratch_model.add(RNNLayer(input_dim=embedding_dim, hidden_dim=rnn_units, bidirectional=is_bidirectional))\n",
    "        scratch_model.add(DropoutLayer(dropout_rate=0.2))\n",
    "        \n",
    "        # Second RNN layer\n",
    "        second_layer_input_dim = rnn_units * 2 if is_bidirectional else rnn_units\n",
    "        second_layer_units = rnn_units // 2  # Half the units\n",
    "        scratch_model.add(RNNLayer(input_dim=second_layer_input_dim, hidden_dim=second_layer_units, bidirectional=is_bidirectional))\n",
    "        scratch_model.add(DropoutLayer(dropout_rate=0.2))\n",
    "        \n",
    "        # Third RNN layer\n",
    "        third_layer_input_dim = second_layer_units * 2 if is_bidirectional else second_layer_units\n",
    "        third_layer_units = second_layer_units // 2  # Quarter the original units\n",
    "        scratch_model.add(RNNLayer(input_dim=third_layer_input_dim, hidden_dim=third_layer_units, bidirectional=is_bidirectional))\n",
    "        scratch_model.add(DropoutLayer(dropout_rate=0.2))\n",
    "        \n",
    "        # For dense layer\n",
    "        dense_input_dim = third_layer_units * 2 if is_bidirectional else third_layer_units\n",
    "    \n",
    "    # Add dense layer with softmax activation\n",
    "    scratch_model.add(DenseLayer(input_dim=dense_input_dim, output_dim=num_classes))\n",
    "    scratch_model.add(Softmax())\n",
    "    \n",
    "    # Try to load weights from Keras model\n",
    "    try:\n",
    "        scratch_model.load_weights_from_keras(keras_model)\n",
    "        print(f\"Successfully loaded weights for {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights for {model_name}: {e}\")\n",
    "    \n",
    "    return scratch_model\n",
    "\n",
    "# Build from-scratch models for each Keras model\n",
    "scratch_models = {}\n",
    "\n",
    "for exp_type, models in keras_models.items():\n",
    "    scratch_models[exp_type] = {}\n",
    "    for name, keras_model in models.items():\n",
    "        if keras_model is not None:\n",
    "            print(f\"Building from-scratch model for {name}...\")\n",
    "            scratch_models[exp_type][name] = build_scratch_model(keras_model, name)\n",
    "        else:\n",
    "            scratch_models[exp_type][name] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Keras and From-Scratch Models\n",
    "\n",
    "Now we'll compare the performance of the Keras models and their from-scratch counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Layer_count Models Comparison ===\n",
      "\n",
      "Comparing 1_layer models:\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "  Keras Model Accuracy: 0.5000\n",
      "  Keras Model Macro F1: 0.4917\n",
      "  Scratch Model Accuracy: 0.3525\n",
      "  Scratch Model Macro F1: 0.2698\n",
      "  Model Agreement: 0.4000\n",
      "3\n",
      "\n",
      "Comparing 2_layer models:\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, keras_model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     30\u001b[0m     scratch_model \u001b[38;5;241m=\u001b[39m scratch_models[exp_type]\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mcompare_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscratch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m))\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mcompare_models\u001b[0;34m(keras_model, scratch_model, model_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mComparing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m models:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compare using utility function\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m comparison \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_keras_vs_scratch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscratch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Keras Model Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomparison[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Keras Model Macro F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomparison[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ML/src/notebooks/RNN/../../../src/models/src/models/base_model/utils/evaluation.py:20\u001b[0m, in \u001b[0;36mcompare_keras_vs_scratch\u001b[0;34m(keras_model, scratch_model, x_test, y_test, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompare_keras_vs_scratch\u001b[39m(keras_model, scratch_model, x_test, y_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Get predictions from both models\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     keras_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(keras_model\u001b[38;5;241m.\u001b[39mpredict(x_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     scratch_preds \u001b[38;5;241m=\u001b[39m \u001b[43mscratch_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Evaluate each model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     keras_metrics \u001b[38;5;241m=\u001b[39m evaluate_predictions(y_test, keras_preds)\n",
      "File \u001b[0;32m~/ML/src/notebooks/RNN/../../../src/models/src/models/base_model/base_model.py:16\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m---> 16\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(outputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/ML/src/notebooks/RNN/../../../src/models/src/models/rnn/rnn_model.py:23\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/ML/src/notebooks/RNN/../../../src/models/src/models/rnn/rnn_layer.py:69\u001b[0m, in \u001b[0;36mRNNLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Perform forward propagation for the RNN layer\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m        or (batch_size, hidden_dim*2) if bidirectional=True\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     batch_size, sequence_length, _ \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Initialize hidden state\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     h_forward \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim))\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from src.models.src.models.base_model.utils.evaluation import compare_keras_vs_scratch\n",
    "\n",
    "# Function to compare models\n",
    "def compare_models(keras_model, scratch_model, model_name):\n",
    "    print(\"Masuk compare models\")\n",
    "    if keras_model is None or scratch_model is None:\n",
    "        print(f\"Skipping comparison for {model_name} (model not available)\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nComparing {model_name} models:\")\n",
    "    \n",
    "    # Compare using utility function\n",
    "    comparison = compare_keras_vs_scratch(keras_model, scratch_model, x_test, y_test)\n",
    "    \n",
    "    print(f\"  Keras Model Accuracy: {comparison['keras_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"  Keras Model Macro F1: {comparison['keras_metrics']['macro_f1']:.4f}\")\n",
    "    print(f\"  Scratch Model Accuracy: {comparison['scratch_metrics']['accuracy']:.4f}\")\n",
    "    print(f\"  Scratch Model Macro F1: {comparison['scratch_metrics']['macro_f1']:.4f}\")\n",
    "    print(f\"  Model Agreement: {comparison['model_agreement']:.4f}\")\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "# Compare all models\n",
    "comparison_results = {}\n",
    "\n",
    "for exp_type, models in keras_models.items():\n",
    "    comparison_results[exp_type] = {}\n",
    "    print(f\"\\n=== {exp_type.capitalize()} Models Comparison ===\")\n",
    "    \n",
    "    for name, keras_model in models.items():\n",
    "        scratch_model = scratch_models[exp_type].get(name)\n",
    "        print(len(compare_models(keras_model, scratch_model, name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Model Agreement\n",
    "\n",
    "Let's analyze the agreement between Keras and from-scratch models in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of model agreements\n",
    "agreement_data = []\n",
    "\n",
    "for exp_type, models in comparison_results.items():\n",
    "    for name, comparison in models.items():\n",
    "        if comparison is not None:\n",
    "            agreement_data.append({\n",
    "                \"experiment\": exp_type,\n",
    "                \"model\": name,\n",
    "                \"keras_accuracy\": comparison[\"keras_metrics\"][\"accuracy\"],\n",
    "                \"scratch_accuracy\": comparison[\"scratch_metrics\"][\"accuracy\"],\n",
    "                \"keras_f1\": comparison[\"keras_metrics\"][\"macro_f1\"],\n",
    "                \"scratch_f1\": comparison[\"scratch_metrics\"][\"macro_f1\"],\n",
    "                \"agreement\": comparison[\"model_agreement\"]\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "import pandas as pd\n",
    "agreement_df = pd.DataFrame(agreement_data)\n",
    "print(\"Model Agreement Summary:\")\n",
    "display(agreement_df)\n",
    "\n",
    "# Plot the agreements\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(agreement_df[\"model\"], agreement_df[\"agreement\"], color=\"skyblue\")\n",
    "plt.axhline(y=1.0, color='r', linestyle='-', alpha=0.3)\n",
    "plt.title(\"Keras vs. From-Scratch Model Agreement\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Agreement Rate\")\n",
    "plt.ylim(0.9, 1.01)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Add agreement values on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "             f'{height:.4f}', ha='center', va='bottom', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../output/results/rnn/model_agreement_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference Performance\n",
    "\n",
    "Let's test the batch inference performance of our from-scratch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one model for batch inference testing\n",
    "# Let's use the bidirectional model if available, otherwise use the first available model\n",
    "test_model_name = \"bidirectional\"\n",
    "if test_model_name not in scratch_models[\"direction\"] or scratch_models[\"direction\"][test_model_name] is None:\n",
    "    # Find the first available model\n",
    "    for exp_type, models in scratch_models.items():\n",
    "        for name, model in models.items():\n",
    "            if model is not None:\n",
    "                test_model_name = name\n",
    "                keras_test_model = keras_models[exp_type][name]\n",
    "                scratch_test_model = model\n",
    "                break\n",
    "        if 'keras_test_model' in locals():\n",
    "            break\n",
    "else:\n",
    "    keras_test_model = keras_models[\"direction\"][test_model_name]\n",
    "    scratch_test_model = scratch_models[\"direction\"][test_model_name]\n",
    "\n",
    "if 'keras_test_model' not in locals():\n",
    "    print(\"No models available for batch inference testing.\")\n",
    "else:\n",
    "    print(f\"Using {test_model_name} model for batch inference testing.\")\n",
    "    \n",
    "    # Test batch inference with different batch sizes\n",
    "    batch_sizes = [1, 10, 32, 64, 128]\n",
    "    inference_results = []\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        # Get a batch of data (make sure we don't exceed test set size)\n",
    "        batch_x = x_test[:min(batch_size, len(x_test))]\n",
    "        batch_y = y_test[:min(batch_size, len(y_test))]\n",
    "        \n",
    "        # Run inference with the scratch model\n",
    "        start_time = tf.timestamp()\n",
    "        scratch_preds = scratch_test_model.predict(batch_x)\n",
    "        end_time = tf.timestamp()\n",
    "        scratch_time = (end_time - start_time) * 1000  # Convert to ms\n",
    "        \n",
    "        # Run inference with the Keras model\n",
    "        start_time = tf.timestamp()\n",
    "        keras_preds = np.argmax(keras_test_model.predict(batch_x), axis=1)\n",
    "        end_time = tf.timestamp()\n",
    "        keras_time = (end_time - start_time) * 1000  # Convert to ms\n",
    "        \n",
    "        # Calculate agreement\n",
    "        agreement = np.mean(scratch_preds == keras_preds)\n",
    "        \n",
    "        print(f\"Batch size: {batch_size}\")\n",
    "        print(f\"  Scratch model inference time: {scratch_time:.2f} ms\")\n",
    "        print(f\"  Keras model inference time: {keras_time:.2f} ms\")\n",
    "        print(f\"  Time ratio (Scratch/Keras): {scratch_time/keras_time:.2f}x\")\n",
    "        print(f\"  Agreement: {agreement:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # Store results\n",
    "        inference_results.append({\n",
    "            \"batch_size\": batch_size,\n",
    "            \"scratch_time\": scratch_time,\n",
    "            \"keras_time\": keras_time,\n",
    "            \"time_ratio\": scratch_time/keras_time,\n",
    "            \"agreement\": agreement\n",
    "        })\n",
    "    \n",
    "    # Plot batch inference performance\n",
    "    results_df = pd.DataFrame(inference_results)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot inference times\n",
    "    ax1.plot(results_df[\"batch_size\"], results_df[\"scratch_time\"], 'o-', label=\"Scratch Model\")\n",
    "    ax1.plot(results_df[\"batch_size\"], results_df[\"keras_time\"], 'o-', label=\"Keras Model\")\n",
    "    ax1.set_title(\"Inference Time vs. Batch Size\")\n",
    "    ax1.set_xlabel(\"Batch Size\")\n",
    "    ax1.set_ylabel(\"Inference Time (ms)\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot time ratio\n",
    "    ax2.plot(results_df[\"batch_size\"], results_df[\"time_ratio\"], 'o-', color=\"green\")\n",
    "    ax2.axhline(y=1.0, color='r', linestyle='--', alpha=0.5)\n",
    "    ax2.set_title(\"Time Ratio (Scratch/Keras) vs. Batch Size\")\n",
    "    ax2.set_xlabel(\"Batch Size\")\n",
    "    ax2.set_ylabel(\"Time Ratio\")\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../../output/results/rnn/batch_inference_performance.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've successfully:\n",
    "\n",
    "1. Built from-scratch RNN models that match our trained Keras models\n",
    "2. Loaded weights from the Keras models into our from-scratch implementations\n",
    "3. Compared the performance of both implementations on the test dataset\n",
    "4. Analyzed the batch inference capabilities of our from-scratch models\n",
    "\n",
    "The results demonstrate that our from-scratch RNN implementation:\n",
    "\n",
    "1. Accurately reproduces the behavior of the Keras models with high agreement\n",
    "2. Can handle batch inference efficiently\n",
    "3. Successfully implements all the required components (RNN cells, bidirectionality, etc.)\n",
    "\n",
    "This validates that our understanding of the RNN architecture is correct and that we can implement it from scratch while maintaining compatibility with trained Keras models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
