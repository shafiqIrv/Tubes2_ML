{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN From Scratch Testing - Enhanced Comparison\n",
    "\n",
    "This notebook provides a complete fixed implementation for comparing Keras RNN models with from-scratch implementations, with detailed layer-by-layer comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append('../../../')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fixed RNN Layer Implementation\n",
    "\n",
    "First, let's implement an improved RNN layer that properly supports multi-layer architectures with `return_sequences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLayer:\n",
    "    def __init__(self, input_dim, hidden_dim, bidirectional=False, return_sequences=False):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.return_sequences = return_sequences\n",
    "\n",
    "        # Initialize weights for forward direction\n",
    "        self.initialize_weights(direction=\"forward\")\n",
    "\n",
    "        # Initialize weights for backward direction if bidirectional\n",
    "        if bidirectional:\n",
    "            self.initialize_weights(direction=\"backward\")\n",
    "            \n",
    "        # For layer info display\n",
    "        self.layer_info = {\n",
    "            \"type\": \"RNNLayer\",\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"bidirectional\": bidirectional,\n",
    "            \"return_sequences\": return_sequences\n",
    "        }\n",
    "\n",
    "    def initialize_weights(self, direction=\"forward\"):\n",
    "        \"\"\"Initialize weights for the RNN layer\"\"\"\n",
    "        prefix = direction + \"_\" if self.bidirectional else \"\"\n",
    "\n",
    "        # Input weights\n",
    "        setattr(\n",
    "            self,\n",
    "            f\"{prefix}W\",\n",
    "            np.random.randn(self.input_dim, self.hidden_dim) * 0.01,\n",
    "        )\n",
    "\n",
    "        # Recurrent weights\n",
    "        setattr(\n",
    "            self,\n",
    "            f\"{prefix}U\",\n",
    "            np.random.randn(self.hidden_dim, self.hidden_dim) * 0.01,\n",
    "        )\n",
    "\n",
    "        # Bias\n",
    "        setattr(self, f\"{prefix}b\", np.zeros(self.hidden_dim))\n",
    "\n",
    "    def forward_step(self, x_t, h_prev, direction=\"forward\"):\n",
    "        \"\"\"Perform one step of forward propagation\"\"\"\n",
    "        prefix = direction + \"_\" if self.bidirectional else \"\"\n",
    "\n",
    "        # Get the weights for this direction\n",
    "        W = getattr(self, f\"{prefix}W\")\n",
    "        U = getattr(self, f\"{prefix}U\")\n",
    "        b = getattr(self, f\"{prefix}b\")\n",
    "\n",
    "        # h_t = tanh(W * x_t + U * h_prev + b)\n",
    "        h_t = np.tanh(np.dot(x_t, W) + np.dot(h_prev, U) + b)\n",
    "\n",
    "        return h_t\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Perform forward propagation for the RNN layer\n",
    "\n",
    "        Args:\n",
    "            inputs: numpy array of shape (batch_size, sequence_length, input_dim)\n",
    "                   or (batch_size, sequence_length) if coming directly from embedding\n",
    "\n",
    "        Returns:\n",
    "            numpy array of shape:\n",
    "            - If return_sequences=False:\n",
    "                (batch_size, hidden_dim) if bidirectional=False\n",
    "                (batch_size, hidden_dim*2) if bidirectional=True\n",
    "            - If return_sequences=True:\n",
    "                (batch_size, sequence_length, hidden_dim) if bidirectional=False\n",
    "                (batch_size, sequence_length, hidden_dim*2) if bidirectional=True\n",
    "        \"\"\"\n",
    "        # Handle different input shapes\n",
    "        if len(inputs.shape) == 2:\n",
    "            # If input is 2D, reshape it to 3D by adding a feature dimension\n",
    "            print(f\"Warning: RNN layer received 2D input with shape {inputs.shape}. \"\n",
    "                  f\"Expected 3D input. Reshaping to add feature dimension.\")\n",
    "            batch_size, sequence_length = inputs.shape\n",
    "            inputs = inputs.reshape(batch_size, sequence_length, 1)\n",
    "        \n",
    "        batch_size, sequence_length, input_features = inputs.shape\n",
    "        \n",
    "        # Check if input dimension matches expected dimension\n",
    "        if input_features != self.input_dim:\n",
    "            print(f\"Warning: Input feature dimension {input_features} doesn't match \"\n",
    "                  f\"expected dimension {self.input_dim}. This may cause issues.\")\n",
    "\n",
    "        # Initialize arrays to store all hidden states if returning sequences\n",
    "        if self.return_sequences:\n",
    "            h_forward_seq = np.zeros((batch_size, sequence_length, self.hidden_dim))\n",
    "            if self.bidirectional:\n",
    "                h_backward_seq = np.zeros((batch_size, sequence_length, self.hidden_dim))\n",
    "\n",
    "        # Initialize hidden state for forward pass\n",
    "        h_forward = np.zeros((batch_size, self.hidden_dim))\n",
    "\n",
    "        # Process the sequence in forward direction\n",
    "        for t in range(sequence_length):\n",
    "            h_forward = self.forward_step(\n",
    "                inputs[:, t, :], h_forward, direction=\"forward\"\n",
    "            )\n",
    "            \n",
    "            # If returning sequences, store the hidden state at this time step\n",
    "            if self.return_sequences:\n",
    "                h_forward_seq[:, t, :] = h_forward\n",
    "\n",
    "        # If not bidirectional, return the result based on return_sequences\n",
    "        if not self.bidirectional:\n",
    "            if self.return_sequences:\n",
    "                return h_forward_seq\n",
    "            else:\n",
    "                return h_forward\n",
    "\n",
    "        # For bidirectional RNN, process the sequence in backward direction\n",
    "        h_backward = np.zeros((batch_size, self.hidden_dim))\n",
    "\n",
    "        for t in range(sequence_length - 1, -1, -1):\n",
    "            h_backward = self.forward_step(\n",
    "                inputs[:, t, :], h_backward, direction=\"backward\"\n",
    "            )\n",
    "            \n",
    "            # If returning sequences, store the hidden state at this time step\n",
    "            if self.return_sequences:\n",
    "                h_backward_seq[:, t, :] = h_backward\n",
    "\n",
    "        # Return the result based on return_sequences\n",
    "        if self.return_sequences:\n",
    "            # Concatenate forward and backward hidden states for each time step\n",
    "            return np.concatenate([h_forward_seq, h_backward_seq], axis=2)\n",
    "        else:\n",
    "            # Concatenate just the final hidden states\n",
    "            return np.concatenate([h_forward, h_backward], axis=1)\n",
    "\n",
    "    def load_weights_from_keras(self, keras_layer):\n",
    "        \"\"\"Load weights from a Keras RNN layer\"\"\"\n",
    "        if isinstance(keras_layer, tf.keras.layers.SimpleRNN):\n",
    "            # Keras weights order: [kernel, recurrent_kernel, bias]\n",
    "            weights = keras_layer.get_weights()\n",
    "            \n",
    "            self.W = weights[0]  # Input weights \n",
    "            self.U = weights[1]  # Recurrent weights \n",
    "            self.b = weights[2]  # Bias\n",
    "            \n",
    "            # Also set the return_sequences attribute to match Keras\n",
    "            self.return_sequences = keras_layer.return_sequences\n",
    "            self.layer_info[\"return_sequences\"] = keras_layer.return_sequences\n",
    "            \n",
    "        elif isinstance(keras_layer, tf.keras.layers.Bidirectional):\n",
    "            # Extract weights from forward and backward layers\n",
    "            forward_weights = keras_layer.forward_layer.get_weights()\n",
    "            backward_weights = keras_layer.backward_layer.get_weights()\n",
    "            \n",
    "            # Forward direction\n",
    "            self.forward_W = forward_weights[0]\n",
    "            self.forward_U = forward_weights[1]\n",
    "            self.forward_b = forward_weights[2]\n",
    "            \n",
    "            # Backward direction\n",
    "            self.backward_W = backward_weights[0]\n",
    "            self.backward_U = backward_weights[1]\n",
    "            self.backward_b = backward_weights[2]\n",
    "            \n",
    "            # Also set the return_sequences attribute to match Keras\n",
    "            self.return_sequences = keras_layer.forward_layer.return_sequences\n",
    "            self.layer_info[\"return_sequences\"] = keras_layer.forward_layer.return_sequences\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type for weight loading: {type(keras_layer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fixed RNN Model Implementation\n",
    "\n",
    "Next, let's implement the fixed RNN model class with additional layer inspection capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Perform forward propagation through all layers\n",
    "        \n",
    "        Args:\n",
    "            inputs: numpy array of shape (batch_size, sequence_length)\n",
    "                  or (batch_size, sequence_length, input_dim) if embedding is done externally\n",
    "                  \n",
    "        Returns:\n",
    "            numpy array of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # Print shape before each layer for debugging\n",
    "            print(f\"Layer {i} input shape: {x.shape}\")\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        # Print final output shape\n",
    "        print(f\"Model output shape: {x.shape}\")\n",
    "        return x\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        Predict class labels for input data\n",
    "        \n",
    "        Args:\n",
    "            inputs: numpy array of shape (batch_size, sequence_length)\n",
    "                  or (batch_size, sequence_length, input_dim)\n",
    "                  \n",
    "        Returns:\n",
    "            numpy array of shape (batch_size,) containing class predictions\n",
    "        \"\"\"\n",
    "        outputs = self.forward(inputs)\n",
    "        return np.argmax(outputs, axis=1)\n",
    "    \n",
    "    def load_weights_from_keras(self, keras_model):\n",
    "        \"\"\"Load weights from a Keras model\"\"\"\n",
    "        # Match layers between Keras model and custom model\n",
    "        if len(self.layers) != len(keras_model.layers):\n",
    "            print(f\"Warning: Layer count mismatch: Custom model has {len(self.layers)} layers, \"\n",
    "                  f\"Keras model has {len(keras_model.layers)} layers\")\n",
    "        \n",
    "        # Load weights for each layer\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i < len(keras_model.layers):\n",
    "                if hasattr(layer, 'load_weights_from_keras'):\n",
    "                    try:\n",
    "                        layer.load_weights_from_keras(keras_model.layers[i])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading weights for layer {i}: {e}\")\n",
    "            else:\n",
    "                print(f\"Warning: No corresponding Keras layer for scratch layer {i}\")\n",
    "                \n",
    "    def print_layer_details(self):\n",
    "        \"\"\"Print detailed information about each layer in the model\"\"\"\n",
    "        print(\"\\nScratch Model Layer Details:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Layer #':<8} {'Layer Type':<20} {'Input Dim':<15} {'Output Dim':<15} {'Other Details':<30}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer_type = type(layer).__name__\n",
    "            \n",
    "            # Default values\n",
    "            input_dim = \"N/A\"\n",
    "            output_dim = \"N/A\"\n",
    "            other_details = \"\"\n",
    "            \n",
    "            # Extract info based on layer type\n",
    "            if hasattr(layer, 'input_dim') and hasattr(layer, 'output_dim'):\n",
    "                # For EmbeddingLayer and DenseLayer\n",
    "                input_dim = str(layer.input_dim)\n",
    "                output_dim = str(layer.output_dim)\n",
    "                if hasattr(layer, 'activation') and layer.activation is not None:\n",
    "                    other_details = f\"Activation: {type(layer.activation).__name__}\"\n",
    "                    \n",
    "            elif hasattr(layer, 'input_dim') and hasattr(layer, 'hidden_dim'):\n",
    "                # For RNNLayer\n",
    "                input_dim = str(layer.input_dim)\n",
    "                if layer.bidirectional:\n",
    "                    output_dim = f\"{layer.hidden_dim}*2={layer.hidden_dim*2}\"\n",
    "                else:\n",
    "                    output_dim = str(layer.hidden_dim)\n",
    "                other_details = f\"Bidirectional: {layer.bidirectional}, RetSeq: {layer.return_sequences}\"\n",
    "                \n",
    "            elif hasattr(layer, 'dropout_rate'):\n",
    "                # For DropoutLayer\n",
    "                other_details = f\"Rate: {layer.dropout_rate}\"\n",
    "                \n",
    "            # Print layer info\n",
    "            print(f\"{i:<8} {layer_type:<20} {input_dim:<15} {output_dim:<15} {other_details:<30}\")\n",
    "        \n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Improved Layer Implementations\n",
    "\n",
    "Let's also add detailed layer info to our other layer types for better comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim  # Vocabulary size\n",
    "        self.output_dim = output_dim  # Embedding dimension\n",
    "        self.weights = np.random.randn(input_dim, output_dim) * 0.01\n",
    "        \n",
    "        # For layer info display\n",
    "        self.layer_info = {\n",
    "            \"type\": \"EmbeddingLayer\",\n",
    "            \"input_dim\": input_dim,\n",
    "            \"output_dim\": output_dim\n",
    "        }\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass for embedding layer\"\"\"\n",
    "        batch_size, sequence_length = inputs.shape\n",
    "        output = np.zeros((batch_size, sequence_length, self.output_dim))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for j in range(sequence_length):\n",
    "                token_idx = inputs[i, j]\n",
    "                # Handle out-of-range indices\n",
    "                if token_idx >= self.input_dim:\n",
    "                    token_idx = 0\n",
    "                output[i, j] = self.weights[token_idx]\n",
    "\n",
    "        return output\n",
    "\n",
    "    def load_weights_from_keras(self, keras_layer):\n",
    "        \"\"\"Load weights from a Keras Embedding layer\"\"\"\n",
    "        self.weights = keras_layer.get_weights()[0]\n",
    "        \n",
    "class DenseLayer:\n",
    "    def __init__(self, input_dim, output_dim, activation=None):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "\n",
    "        # Initialize weights if input_dim is provided\n",
    "        if input_dim is not None:\n",
    "            self.weights = np.random.randn(input_dim, output_dim) * 0.01\n",
    "            self.biases = np.zeros(output_dim)\n",
    "        else:\n",
    "            self.weights = None\n",
    "            self.biases = None\n",
    "        \n",
    "        # For layer info display\n",
    "        self.layer_info = {\n",
    "            \"type\": \"DenseLayer\",\n",
    "            \"input_dim\": input_dim,\n",
    "            \"output_dim\": output_dim,\n",
    "            \"activation\": type(activation).__name__ if activation else None\n",
    "        }\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass for dense layer\"\"\"\n",
    "        # Initialize weights if needed\n",
    "        if self.weights is None and inputs.shape[1] is not None:\n",
    "            self.input_dim = inputs.shape[1]\n",
    "            self.weights = np.random.randn(self.input_dim, self.output_dim) * 0.01\n",
    "            self.biases = np.zeros(self.output_dim)\n",
    "            self.layer_info[\"input_dim\"] = self.input_dim\n",
    "\n",
    "        output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "        if self.activation:\n",
    "            output = self.activation.forward(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def load_weights_from_keras(self, keras_layer):\n",
    "        \"\"\"Load weights from a Keras Dense layer\"\"\"\n",
    "        weights = keras_layer.get_weights()\n",
    "        if len(weights) >= 2:\n",
    "            self.weights = weights[0]\n",
    "            self.biases = weights[1]\n",
    "            \n",
    "class DropoutLayer:\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "        self.training = True\n",
    "        \n",
    "        # For layer info display\n",
    "        self.layer_info = {\n",
    "            \"type\": \"DropoutLayer\",\n",
    "            \"dropout_rate\": dropout_rate\n",
    "        }\n",
    "    \n",
    "    def forward(self, inputs, training=True):\n",
    "        \"\"\"Forward pass for dropout layer\"\"\"\n",
    "        self.training = training\n",
    "        \n",
    "        if not training:\n",
    "            return inputs\n",
    "        \n",
    "        # Generate dropout mask (1: keep, 0: drop)\n",
    "        self.mask = np.random.binomial(1, 1 - self.dropout_rate, size=inputs.shape) / (1 - self.dropout_rate)\n",
    "        \n",
    "        # Apply mask to inputs\n",
    "        return inputs * self.mask\n",
    "    \n",
    "    def load_weights_from_keras(self, keras_layer):\n",
    "        \"\"\"Load configuration from a Keras Dropout layer\"\"\"\n",
    "        self.dropout_rate = keras_layer.rate\n",
    "        self.layer_info[\"dropout_rate\"] = keras_layer.rate\n",
    "        \n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        # For layer info display\n",
    "        self.layer_info = {\n",
    "            \"type\": \"Softmax\"\n",
    "        }\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass for softmax activation\"\"\"\n",
    "        exp_shifted = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        self.outputs = exp_shifted / np.sum(exp_shifted, axis=1, keepdims=True)\n",
    "        return self.outputs\n",
    "    \n",
    "    def load_weights_from_keras(self, keras_layer):\n",
    "        \"\"\"No weights to load for Softmax\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading\n",
    "\n",
    "Now let's load the NusaX dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2836\n",
      "Number of classes: 3\n",
      "Maximum sequence length: 100\n",
      "Test data shape: (400, 100)\n"
     ]
    }
   ],
   "source": [
    "from src.models.src.models.base_model.utils.nusax_loader import NusaXLoader\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = NusaXLoader(\n",
    "    batch_size=32,\n",
    "    max_sequence_length=100,\n",
    "    vocab_size=10000,\n",
    "    add=True  # Add '../' to path\n",
    ")\n",
    "\n",
    "# Load datasets and initialize vocabulary \n",
    "train_dataset = data_loader.get_dataset(\"train\")  # This initializes the vocabulary\n",
    "val_dataset = data_loader.get_dataset(\"valid\")\n",
    "test_dataset = data_loader.get_dataset(\"test\")\n",
    "\n",
    "# Get raw test data for evaluation\n",
    "x_test, y_test = data_loader.get_vectorized_data(\"test\")\n",
    "\n",
    "# Get dataset characteristics\n",
    "vocab_size = len(data_loader.get_vocabulary())\n",
    "num_classes = data_loader.num_classes\n",
    "max_sequence_length = data_loader.max_sequence_length\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Maximum sequence length: {max_sequence_length}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enhanced Model Builder and Layer Comparison\n",
    "\n",
    "Let's create an improved function to build scratch models and compare layers side by side with Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scratch_model_for_keras(keras_model):\n",
    "    \"\"\"\n",
    "    Build a scratch model that matches the architecture of a given Keras model\n",
    "    \n",
    "    Args:\n",
    "        keras_model: The Keras model to match\n",
    "        \n",
    "    Returns:\n",
    "        A scratch model with matching architecture\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout, Bidirectional\n",
    "    \n",
    "    # Create scratch model\n",
    "    scratch_model = RNNModel()\n",
    "    \n",
    "    # Display Keras model layer details\n",
    "    print(\"\\nKeras Model Layer Details:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Layer #':<8} {'Layer Type':<20} {'Input Shape':<20} {'Output Shape':<20} {'Config':<30}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, layer in enumerate(keras_model.layers):\n",
    "        layer_type = layer.__class__.__name__\n",
    "        input_shape = str(layer.input_shape) if hasattr(layer, 'input_shape') else \"N/A\"\n",
    "        output_shape = str(layer.output_shape) if hasattr(layer, 'output_shape') else \"N/A\"\n",
    "        \n",
    "        # Extract config details\n",
    "        config = \"\"\n",
    "        if isinstance(layer, Embedding):\n",
    "            config = f\"in_dim={layer.input_dim}, out_dim={layer.output_dim}\"\n",
    "        elif isinstance(layer, SimpleRNN):\n",
    "            config = f\"units={layer.units}, ret_seq={layer.return_sequences}\"\n",
    "        elif isinstance(layer, Bidirectional):\n",
    "            config = f\"units={layer.forward_layer.units}, ret_seq={layer.forward_layer.return_sequences}\"\n",
    "        elif isinstance(layer, Dropout):\n",
    "            config = f\"rate={layer.rate}\"\n",
    "        elif isinstance(layer, Dense):\n",
    "            config = f\"units={layer.units}, act={layer.activation.__name__ if hasattr(layer.activation, '__name__') else layer.activation}\"\n",
    "            \n",
    "        print(f\"{i:<8} {layer_type:<20} {input_shape:<20} {output_shape:<20} {config:<30}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Analyze the Keras model and build a matching scratch model\n",
    "    for i, layer in enumerate(keras_model.layers):\n",
    "        print(f\"Processing layer {i}: {layer.__class__.__name__}\")\n",
    "        \n",
    "        if isinstance(layer, Embedding):\n",
    "            # Add embedding layer\n",
    "            scratch_model.add(EmbeddingLayer(\n",
    "                input_dim=layer.input_dim,\n",
    "                output_dim=layer.output_dim\n",
    "            ))\n",
    "            print(f\"  Added Embedding layer: {layer.input_dim} → {layer.output_dim}\")\n",
    "            \n",
    "        elif isinstance(layer, SimpleRNN):\n",
    "            # Get the input dimension\n",
    "            if i > 0 and isinstance(keras_model.layers[i-1], SimpleRNN):\n",
    "                # If previous layer is RNN, input dim is its units\n",
    "                input_dim = keras_model.layers[i-1].units\n",
    "            elif i > 0 and isinstance(keras_model.layers[i-1], Bidirectional):\n",
    "                # If previous layer is Bidirectional, input dim is 2x its units\n",
    "                input_dim = keras_model.layers[i-1].forward_layer.units * 2\n",
    "            elif i > 0 and isinstance(keras_model.layers[i-1], Embedding):\n",
    "                # If previous layer is Embedding, input dim is its output dim\n",
    "                input_dim = keras_model.layers[i-1].output_dim\n",
    "            else:\n",
    "                # Default fallback\n",
    "                input_dim = layer.input_shape[-1] if hasattr(layer, 'input_shape') else 100\n",
    "            \n",
    "            # Add RNN layer\n",
    "            scratch_model.add(RNNLayer(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=layer.units,\n",
    "                bidirectional=False,\n",
    "                return_sequences=layer.return_sequences\n",
    "            ))\n",
    "            print(f\"  Added RNN layer: {input_dim} → {layer.units} (return_sequences={layer.return_sequences})\")\n",
    "            \n",
    "        elif isinstance(layer, Bidirectional):\n",
    "            # Similar logic for Bidirectional layers\n",
    "            if i > 0 and isinstance(keras_model.layers[i-1], SimpleRNN):\n",
    "                input_dim = keras_model.layers[i-1].units\n",
    "            elif i > 0 and isinstance(keras_model.layers[i-1], Bidirectional):\n",
    "                input_dim = keras_model.layers[i-1].forward_layer.units * 2\n",
    "            elif i > 0 and isinstance(keras_model.layers[i-1], Embedding):\n",
    "                input_dim = keras_model.layers[i-1].output_dim\n",
    "            else:\n",
    "                input_dim = layer.input_shape[-1] if hasattr(layer, 'input_shape') else 100\n",
    "            \n",
    "            scratch_model.add(RNNLayer(\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=layer.forward_layer.units,\n",
    "                bidirectional=True,\n",
    "                return_sequences=layer.forward_layer.return_sequences\n",
    "            ))\n",
    "            print(f\"  Added Bidirectional RNN layer: {input_dim} → {layer.forward_layer.units} \"\n",
    "                  f\"(return_sequences={layer.forward_layer.return_sequences})\")\n",
    "            \n",
    "        elif isinstance(layer, Dropout):\n",
    "            # Add dropout layer\n",
    "            scratch_model.add(DropoutLayer(dropout_rate=layer.rate))\n",
    "            print(f\"  Added Dropout layer: rate={layer.rate}\")\n",
    "            \n",
    "        elif isinstance(layer, Dense):\n",
    "            # Get the input dimension\n",
    "            if i > 0 and isinstance(keras_model.layers[i-1], SimpleRNN):\n",
    "                input_dim = keras_model.layers[i-1].units\n",
    "            elif i > 0 and isinstance(keras_model.layers[i-1], Bidirectional):\n",
    "                input_dim = keras_model.layers[i-1].forward_layer.units * 2\n",
    "            elif i > 0 and isinstance(keras_model.layers[i-1], Dropout):\n",
    "                # Look for the layer before dropout\n",
    "                prev_idx = i - 2\n",
    "                while prev_idx >= 0 and isinstance(keras_model.layers[prev_idx], Dropout):\n",
    "                    prev_idx -= 1\n",
    "                \n",
    "                if prev_idx >= 0:\n",
    "                    if isinstance(keras_model.layers[prev_idx], SimpleRNN):\n",
    "                        input_dim = keras_model.layers[prev_idx].units\n",
    "                    elif isinstance(keras_model.layers[prev_idx], Bidirectional):\n",
    "                        input_dim = keras_model.layers[prev_idx].forward_layer.units * 2\n",
    "                    else:\n",
    "                        input_dim = layer.input_shape[-1] if hasattr(layer, 'input_shape') else 128\n",
    "                else:\n",
    "                    input_dim = layer.input_shape[-1] if hasattr(layer, 'input_shape') else 128\n",
    "            else:\n",
    "                input_dim = layer.input_shape[-1] if hasattr(layer, 'input_shape') else 128\n",
    "            \n",
    "            # Add dense layer\n",
    "            scratch_model.add(DenseLayer(\n",
    "                input_dim=input_dim,\n",
    "                output_dim=layer.units,\n",
    "                activation=None\n",
    "            ))\n",
    "            print(f\"  Added Dense layer: {input_dim} → {layer.units}\")\n",
    "            \n",
    "            # If this is the final layer with softmax activation, add a separate Softmax layer\n",
    "            if (i == len(keras_model.layers) - 1 and \n",
    "                hasattr(layer, 'activation') and \n",
    "                getattr(layer.activation, '__name__', None) == 'softmax'):\n",
    "                scratch_model.add(Softmax())\n",
    "                print(f\"  Added Softmax activation\")\n",
    "    \n",
    "    # Print the scratch model structure\n",
    "    scratch_model.print_layer_details()\n",
    "    \n",
    "    # Compare Keras and scratch model layer by layer\n",
    "    print(\"\\nLayer-by-Layer Comparison:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Layer #':<8} {'Keras Type':<20} {'Keras Config':<30} {'Scratch Type':<20} {'Scratch Config':<30}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for i in range(max(len(keras_model.layers), len(scratch_model.layers))):\n",
    "        # Keras layer info\n",
    "        if i < len(keras_model.layers):\n",
    "            k_layer = keras_model.layers[i]\n",
    "            k_type = k_layer.__class__.__name__\n",
    "            \n",
    "            # Extract config\n",
    "            k_config = \"\"\n",
    "            if isinstance(k_layer, Embedding):\n",
    "                k_config = f\"in_dim={k_layer.input_dim}, out_dim={k_layer.output_dim}\"\n",
    "            elif isinstance(k_layer, SimpleRNN):\n",
    "                k_config = f\"units={k_layer.units}, ret_seq={k_layer.return_sequences}\"\n",
    "            elif isinstance(k_layer, Bidirectional):\n",
    "                k_config = f\"units={k_layer.forward_layer.units}, ret_seq={k_layer.forward_layer.return_sequences}\"\n",
    "            elif isinstance(k_layer, Dropout):\n",
    "                k_config = f\"rate={k_layer.rate}\"\n",
    "            elif isinstance(k_layer, Dense):\n",
    "                k_config = f\"units={k_layer.units}, act={k_layer.activation.__name__ if hasattr(k_layer.activation, '__name__') else k_layer.activation}\"\n",
    "        else:\n",
    "            k_type = \"N/A\"\n",
    "            k_config = \"N/A\"\n",
    "        \n",
    "        # Scratch layer info\n",
    "        if i < len(scratch_model.layers):\n",
    "            s_layer = scratch_model.layers[i]\n",
    "            s_type = type(s_layer).__name__\n",
    "            \n",
    "            # Extract config\n",
    "            s_config = \"\"\n",
    "            if hasattr(s_layer, 'input_dim') and hasattr(s_layer, 'output_dim'):\n",
    "                s_config = f\"in_dim={s_layer.input_dim}, out_dim={s_layer.output_dim}\"\n",
    "                if hasattr(s_layer, 'activation') and s_layer.activation is not None:\n",
    "                    s_config += f\", act={type(s_layer.activation).__name__}\"\n",
    "            elif hasattr(s_layer, 'input_dim') and hasattr(s_layer, 'hidden_dim'):\n",
    "                s_config = f\"in_dim={s_layer.input_dim}, hid_dim={s_layer.hidden_dim}\"\n",
    "                s_config += f\", bidir={s_layer.bidirectional}, ret_seq={s_layer.return_sequences}\"\n",
    "            elif hasattr(s_layer, 'dropout_rate'):\n",
    "                s_config = f\"rate={s_layer.dropout_rate}\"\n",
    "        else:\n",
    "            s_type = \"N/A\"\n",
    "            s_config = \"N/A\"\n",
    "        \n",
    "        # Print comparison row\n",
    "        print(f\"{i:<8} {k_type:<20} {k_config:<30} {s_type:<20} {s_config:<30}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    return scratch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison Function\n",
    "\n",
    "Let's create a function to compare Keras and scratch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(keras_model, scratch_model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Compare Keras and scratch models\n",
    "    \n",
    "    Args:\n",
    "        keras_model: The Keras model\n",
    "        scratch_model: The scratch model\n",
    "        x_test: Test data\n",
    "        y_test: Test labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Comparison results\n",
    "    \"\"\"\n",
    "    # Get predictions from both models\n",
    "    print(\"Getting predictions from Keras model...\")\n",
    "    keras_preds = np.argmax(keras_model.predict(x_test), axis=1)\n",
    "    \n",
    "    print(\"Getting predictions from scratch model...\")\n",
    "    scratch_preds = scratch_model.predict(x_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    keras_acc = np.mean(keras_preds == y_test)\n",
    "    keras_f1 = f1_score(y_test, keras_preds, average='macro')\n",
    "    \n",
    "    scratch_acc = np.mean(scratch_preds == y_test)\n",
    "    scratch_f1 = f1_score(y_test, scratch_preds, average='macro')\n",
    "    \n",
    "    agreement = np.mean(keras_preds == scratch_preds)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nKeras Model Accuracy: {keras_acc:.4f}\")\n",
    "    print(f\"Keras Model Macro F1: {keras_f1:.4f}\")\n",
    "    print(f\"Scratch Model Accuracy: {scratch_acc:.4f}\")\n",
    "    print(f\"Scratch Model Macro F1: {scratch_f1:.4f}\")\n",
    "    print(f\"Model Agreement: {agreement:.4f}\")\n",
    "    \n",
    "    # Print prediction disagreements\n",
    "    if agreement < 1.0:\n",
    "        disagreement_indices = np.where(keras_preds != scratch_preds)[0]\n",
    "        print(f\"\\nFound {len(disagreement_indices)} prediction disagreements\")\n",
    "        \n",
    "        print(\"Sample disagreements:\")\n",
    "        for idx in disagreement_indices[:5]:  # Show first 5 disagreements\n",
    "            print(f\"  Index {idx}: Keras pred={keras_preds[idx]}, Scratch pred={scratch_preds[idx]}, True={y_test[idx]}\")\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'keras_metrics': {\n",
    "            'accuracy': keras_acc,\n",
    "            'macro_f1': keras_f1\n",
    "        },\n",
    "        'scratch_metrics': {\n",
    "            'accuracy': scratch_acc,\n",
    "            'macro_f1': scratch_f1\n",
    "        },\n",
    "        'model_agreement': agreement,\n",
    "        'keras_preds': keras_preds,\n",
    "        'scratch_preds': scratch_preds\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load and Compare Models\n",
    "\n",
    "Now let's load the trained Keras models and build matching scratch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing 1_layer model ===\n",
      "Successfully loaded Keras model from ../../output/models/rnn/1_layer_rnn.keras\n",
      "\n",
      "Keras Model Layer Details:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer #  Layer Type           Input Shape          Output Shape         Config                        \n",
      "--------------------------------------------------------------------------------\n",
      "0        Embedding            N/A                  N/A                  in_dim=2836, out_dim=100      \n",
      "1        SimpleRNN            N/A                  N/A                  units=128, ret_seq=False      \n",
      "2        Dropout              N/A                  N/A                  rate=0.2                      \n",
      "3        Dense                N/A                  N/A                  units=3, act=softmax          \n",
      "--------------------------------------------------------------------------------\n",
      "Processing layer 0: Embedding\n",
      "  Added Embedding layer: 2836 → 100\n",
      "Processing layer 1: SimpleRNN\n",
      "  Added RNN layer: 100 → 128 (return_sequences=False)\n",
      "Processing layer 2: Dropout\n",
      "  Added Dropout layer: rate=0.2\n",
      "Processing layer 3: Dense\n",
      "  Added Dense layer: 128 → 3\n",
      "  Added Softmax activation\n",
      "\n",
      "Scratch Model Layer Details:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer #  Layer Type           Input Dim       Output Dim      Other Details                 \n",
      "--------------------------------------------------------------------------------\n",
      "0        EmbeddingLayer       2836            100                                           \n",
      "1        RNNLayer             100             128             Bidirectional: False, RetSeq: False\n",
      "2        DropoutLayer         N/A             N/A             Rate: 0.2                     \n",
      "3        DenseLayer           128             3                                             \n",
      "4        Softmax              N/A             N/A                                           \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Layer-by-Layer Comparison:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Layer #  Keras Type           Keras Config                   Scratch Type         Scratch Config                \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0        Embedding            in_dim=2836, out_dim=100       EmbeddingLayer       in_dim=2836, out_dim=100      \n",
      "1        SimpleRNN            units=128, ret_seq=False       RNNLayer             in_dim=100, hid_dim=128, bidir=False, ret_seq=False\n",
      "2        Dropout              rate=0.2                       DropoutLayer         rate=0.2                      \n",
      "3        Dense                units=3, act=softmax           DenseLayer           in_dim=128, out_dim=3         \n",
      "4        N/A                  N/A                            Softmax                                            \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Warning: Layer count mismatch: Custom model has 5 layers, Keras model has 4 layers\n",
      "Warning: No corresponding Keras layer for scratch layer 4\n",
      "Successfully loaded weights from Keras model\n",
      "Getting predictions from Keras model...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
      "Getting predictions from scratch model...\n",
      "Layer 0 input shape: (400, 100)\n",
      "Layer 1 input shape: (400, 100, 100)\n",
      "Layer 2 input shape: (400, 128)\n",
      "Layer 3 input shape: (400, 128)\n",
      "Layer 4 input shape: (400, 3)\n",
      "Model output shape: (400, 3)\n",
      "\n",
      "Keras Model Accuracy: 0.5000\n",
      "Keras Model Macro F1: 0.4917\n",
      "Scratch Model Accuracy: 0.4500\n",
      "Scratch Model Macro F1: 0.3992\n",
      "Model Agreement: 0.4400\n",
      "\n",
      "Found 224 prediction disagreements\n",
      "Sample disagreements:\n",
      "  Index 0: Keras pred=2, Scratch pred=0, True=2\n",
      "  Index 1: Keras pred=1, Scratch pred=0, True=1\n",
      "  Index 2: Keras pred=2, Scratch pred=0, True=0\n",
      "  Index 4: Keras pred=0, Scratch pred=2, True=1\n",
      "  Index 5: Keras pred=0, Scratch pred=1, True=0\n",
      "\n",
      "=== Comparing 2_layer model ===\n",
      "Successfully loaded Keras model from ../../output/models/rnn/2_layer_rnn.keras\n",
      "\n",
      "Keras Model Layer Details:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer #  Layer Type           Input Shape          Output Shape         Config                        \n",
      "--------------------------------------------------------------------------------\n",
      "0        Embedding            N/A                  N/A                  in_dim=2836, out_dim=100      \n",
      "1        SimpleRNN            N/A                  N/A                  units=128, ret_seq=True       \n",
      "2        Dropout              N/A                  N/A                  rate=0.2                      \n",
      "3        SimpleRNN            N/A                  N/A                  units=64, ret_seq=False       \n",
      "4        Dropout              N/A                  N/A                  rate=0.2                      \n",
      "5        Dense                N/A                  N/A                  units=3, act=softmax          \n",
      "--------------------------------------------------------------------------------\n",
      "Processing layer 0: Embedding\n",
      "  Added Embedding layer: 2836 → 100\n",
      "Processing layer 1: SimpleRNN\n",
      "  Added RNN layer: 100 → 128 (return_sequences=True)\n",
      "Processing layer 2: Dropout\n",
      "  Added Dropout layer: rate=0.2\n",
      "Processing layer 3: SimpleRNN\n",
      "  Added RNN layer: 100 → 64 (return_sequences=False)\n",
      "Processing layer 4: Dropout\n",
      "  Added Dropout layer: rate=0.2\n",
      "Processing layer 5: Dense\n",
      "  Added Dense layer: 64 → 3\n",
      "  Added Softmax activation\n",
      "\n",
      "Scratch Model Layer Details:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer #  Layer Type           Input Dim       Output Dim      Other Details                 \n",
      "--------------------------------------------------------------------------------\n",
      "0        EmbeddingLayer       2836            100                                           \n",
      "1        RNNLayer             100             128             Bidirectional: False, RetSeq: True\n",
      "2        DropoutLayer         N/A             N/A             Rate: 0.2                     \n",
      "3        RNNLayer             100             64              Bidirectional: False, RetSeq: False\n",
      "4        DropoutLayer         N/A             N/A             Rate: 0.2                     \n",
      "5        DenseLayer           64              3                                             \n",
      "6        Softmax              N/A             N/A                                           \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Layer-by-Layer Comparison:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Layer #  Keras Type           Keras Config                   Scratch Type         Scratch Config                \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0        Embedding            in_dim=2836, out_dim=100       EmbeddingLayer       in_dim=2836, out_dim=100      \n",
      "1        SimpleRNN            units=128, ret_seq=True        RNNLayer             in_dim=100, hid_dim=128, bidir=False, ret_seq=True\n",
      "2        Dropout              rate=0.2                       DropoutLayer         rate=0.2                      \n",
      "3        SimpleRNN            units=64, ret_seq=False        RNNLayer             in_dim=100, hid_dim=64, bidir=False, ret_seq=False\n",
      "4        Dropout              rate=0.2                       DropoutLayer         rate=0.2                      \n",
      "5        Dense                units=3, act=softmax           DenseLayer           in_dim=64, out_dim=3          \n",
      "6        N/A                  N/A                            Softmax                                            \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Warning: Layer count mismatch: Custom model has 7 layers, Keras model has 6 layers\n",
      "Warning: No corresponding Keras layer for scratch layer 6\n",
      "Successfully loaded weights from Keras model\n",
      "Getting predictions from Keras model...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
      "Getting predictions from scratch model...\n",
      "Layer 0 input shape: (400, 100)\n",
      "Layer 1 input shape: (400, 100, 100)\n",
      "Layer 2 input shape: (400, 100, 128)\n",
      "Layer 3 input shape: (400, 100, 128)\n",
      "Warning: Input feature dimension 128 doesn't match expected dimension 100. This may cause issues.\n",
      "Layer 4 input shape: (400, 64)\n",
      "Layer 5 input shape: (400, 64)\n",
      "Layer 6 input shape: (400, 3)\n",
      "Model output shape: (400, 3)\n",
      "\n",
      "Keras Model Accuracy: 0.4950\n",
      "Keras Model Macro F1: 0.4906\n",
      "Scratch Model Accuracy: 0.4525\n",
      "Scratch Model Macro F1: 0.4399\n",
      "Model Agreement: 0.3875\n",
      "\n",
      "Found 245 prediction disagreements\n",
      "Sample disagreements:\n",
      "  Index 5: Keras pred=1, Scratch pred=0, True=0\n",
      "  Index 7: Keras pred=2, Scratch pred=1, True=0\n",
      "  Index 8: Keras pred=1, Scratch pred=2, True=2\n",
      "  Index 9: Keras pred=2, Scratch pred=0, True=2\n",
      "  Index 10: Keras pred=0, Scratch pred=1, True=1\n",
      "\n",
      "=== Comparing 3_layer model ===\n",
      "Successfully loaded Keras model from ../../output/models/rnn/3_layer_rnn.keras\n",
      "\n",
      "Keras Model Layer Details:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer #  Layer Type           Input Shape          Output Shape         Config                        \n",
      "--------------------------------------------------------------------------------\n",
      "0        Embedding            N/A                  N/A                  in_dim=2836, out_dim=100      \n",
      "1        SimpleRNN            N/A                  N/A                  units=128, ret_seq=True       \n",
      "2        Dropout              N/A                  N/A                  rate=0.2                      \n",
      "3        SimpleRNN            N/A                  N/A                  units=64, ret_seq=True        \n",
      "4        Dropout              N/A                  N/A                  rate=0.2                      \n",
      "5        SimpleRNN            N/A                  N/A                  units=32, ret_seq=False       \n",
      "6        Dropout              N/A                  N/A                  rate=0.2                      \n",
      "7        Dense                N/A                  N/A                  units=3, act=softmax          \n",
      "--------------------------------------------------------------------------------\n",
      "Processing layer 0: Embedding\n",
      "  Added Embedding layer: 2836 → 100\n",
      "Processing layer 1: SimpleRNN\n",
      "  Added RNN layer: 100 → 128 (return_sequences=True)\n",
      "Processing layer 2: Dropout\n",
      "  Added Dropout layer: rate=0.2\n",
      "Processing layer 3: SimpleRNN\n",
      "  Added RNN layer: 100 → 64 (return_sequences=True)\n",
      "Processing layer 4: Dropout\n",
      "  Added Dropout layer: rate=0.2\n",
      "Processing layer 5: SimpleRNN\n",
      "  Added RNN layer: 100 → 32 (return_sequences=False)\n",
      "Processing layer 6: Dropout\n",
      "  Added Dropout layer: rate=0.2\n",
      "Processing layer 7: Dense\n",
      "  Added Dense layer: 32 → 3\n",
      "  Added Softmax activation\n",
      "\n",
      "Scratch Model Layer Details:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer #  Layer Type           Input Dim       Output Dim      Other Details                 \n",
      "--------------------------------------------------------------------------------\n",
      "0        EmbeddingLayer       2836            100                                           \n",
      "1        RNNLayer             100             128             Bidirectional: False, RetSeq: True\n",
      "2        DropoutLayer         N/A             N/A             Rate: 0.2                     \n",
      "3        RNNLayer             100             64              Bidirectional: False, RetSeq: True\n",
      "4        DropoutLayer         N/A             N/A             Rate: 0.2                     \n",
      "5        RNNLayer             100             32              Bidirectional: False, RetSeq: False\n",
      "6        DropoutLayer         N/A             N/A             Rate: 0.2                     \n",
      "7        DenseLayer           32              3                                             \n",
      "8        Softmax              N/A             N/A                                           \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Layer-by-Layer Comparison:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Layer #  Keras Type           Keras Config                   Scratch Type         Scratch Config                \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0        Embedding            in_dim=2836, out_dim=100       EmbeddingLayer       in_dim=2836, out_dim=100      \n",
      "1        SimpleRNN            units=128, ret_seq=True        RNNLayer             in_dim=100, hid_dim=128, bidir=False, ret_seq=True\n",
      "2        Dropout              rate=0.2                       DropoutLayer         rate=0.2                      \n",
      "3        SimpleRNN            units=64, ret_seq=True         RNNLayer             in_dim=100, hid_dim=64, bidir=False, ret_seq=True\n",
      "4        Dropout              rate=0.2                       DropoutLayer         rate=0.2                      \n",
      "5        SimpleRNN            units=32, ret_seq=False        RNNLayer             in_dim=100, hid_dim=32, bidir=False, ret_seq=False\n",
      "6        Dropout              rate=0.2                       DropoutLayer         rate=0.2                      \n",
      "7        Dense                units=3, act=softmax           DenseLayer           in_dim=32, out_dim=3          \n",
      "8        N/A                  N/A                            Softmax                                            \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Warning: Layer count mismatch: Custom model has 9 layers, Keras model has 8 layers\n",
      "Warning: No corresponding Keras layer for scratch layer 8\n",
      "Successfully loaded weights from Keras model\n",
      "Getting predictions from Keras model...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step\n",
      "Getting predictions from scratch model...\n",
      "Layer 0 input shape: (400, 100)\n",
      "Layer 1 input shape: (400, 100, 100)\n",
      "Layer 2 input shape: (400, 100, 128)\n",
      "Layer 3 input shape: (400, 100, 128)\n",
      "Warning: Input feature dimension 128 doesn't match expected dimension 100. This may cause issues.\n",
      "Layer 4 input shape: (400, 100, 64)\n",
      "Layer 5 input shape: (400, 100, 64)\n",
      "Warning: Input feature dimension 64 doesn't match expected dimension 100. This may cause issues.\n",
      "Layer 6 input shape: (400, 32)\n",
      "Layer 7 input shape: (400, 32)\n",
      "Layer 8 input shape: (400, 3)\n",
      "Model output shape: (400, 3)\n",
      "\n",
      "Keras Model Accuracy: 0.6225\n",
      "Keras Model Macro F1: 0.5728\n",
      "Scratch Model Accuracy: 0.3200\n",
      "Scratch Model Macro F1: 0.2952\n",
      "Model Agreement: 0.3725\n",
      "\n",
      "Found 251 prediction disagreements\n",
      "Sample disagreements:\n",
      "  Index 1: Keras pred=2, Scratch pred=0, True=1\n",
      "  Index 4: Keras pred=0, Scratch pred=1, True=1\n",
      "  Index 7: Keras pred=2, Scratch pred=1, True=0\n",
      "  Index 8: Keras pred=1, Scratch pred=0, True=2\n",
      "  Index 9: Keras pred=2, Scratch pred=0, True=2\n"
     ]
    }
   ],
   "source": [
    "# Paths to your trained models\n",
    "model_paths = {\n",
    "    \"1_layer\": \"../../output/models/rnn/1_layer_rnn.keras\",\n",
    "    \"2_layer\": \"../../output/models/rnn/2_layer_rnn.keras\",\n",
    "    \"3_layer\": \"../../output/models/rnn/3_layer_rnn.keras\"\n",
    "}\n",
    "\n",
    "# Loop through each model and compare\n",
    "results = {}\n",
    "\n",
    "for model_name, model_path in model_paths.items():\n",
    "    print(f\"\\n=== Comparing {model_name} model ===\")\n",
    "    \n",
    "    # Try to load the Keras model\n",
    "    try:\n",
    "        keras_model = load_model(model_path)\n",
    "        print(f\"Successfully loaded Keras model from {model_path}\")\n",
    "        \n",
    "        # Build corresponding scratch model with detailed comparison\n",
    "        scratch_model = build_scratch_model_for_keras(keras_model)\n",
    "        \n",
    "        # Load weights\n",
    "        try:\n",
    "            scratch_model.load_weights_from_keras(keras_model)\n",
    "            print(\"Successfully loaded weights from Keras model\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading weights: {e}\")\n",
    "        \n",
    "        # Compare models\n",
    "        comparison = compare_models(keras_model, scratch_model, x_test, y_test)\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name] = comparison\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results\n",
    "\n",
    "Let's visualize the comparison results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Keras Accuracy</th>\n",
       "      <th>Keras F1</th>\n",
       "      <th>Scratch Accuracy</th>\n",
       "      <th>Scratch F1</th>\n",
       "      <th>Agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_layer</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.399220</td>\n",
       "      <td>0.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_layer</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.490606</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>0.439949</td>\n",
       "      <td>0.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_layer</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.572826</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.295161</td>\n",
       "      <td>0.3725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Keras Accuracy  Keras F1  Scratch Accuracy  Scratch F1  Agreement\n",
       "0  1_layer          0.5000  0.491713            0.4500    0.399220     0.4400\n",
       "1  2_layer          0.4950  0.490606            0.4525    0.439949     0.3875\n",
       "2  3_layer          0.6225  0.572826            0.3200    0.295161     0.3725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a summary of model performances\n",
    "if results:\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Extract metrics for each model\n",
    "    metrics_data = []\n",
    "    for model_name, result in results.items():\n",
    "        metrics_data.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Keras Accuracy\": result[\"keras_metrics\"][\"accuracy\"],\n",
    "            \"Keras F1\": result[\"keras_metrics\"][\"macro_f1\"],\n",
    "            \"Scratch Accuracy\": result[\"scratch_metrics\"][\"accuracy\"],\n",
    "            \"Scratch F1\": result[\"scratch_metrics\"][\"macro_f1\"],\n",
    "            \"Agreement\": result[\"model_agreement\"]\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and display\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    print(\"Model Performance Summary:\")\n",
    "    display(metrics_df)\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = metrics_df[\"Model\"]\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.15\n",
    "    \n",
    "    # Plot bars\n",
    "    plt.bar(x - width*2, metrics_df[\"Keras Accuracy\"], width, label=\"Keras Accuracy\")\n",
    "    plt.bar(x - width, metrics_df[\"Keras F1\"], width, label=\"Keras F1\")\n",
    "    plt.bar(x, metrics_df[\"Scratch Accuracy\"], width, label=\"Scratch Accuracy\")\n",
    "    plt.bar(x + width, metrics_df[\"Scratch F1\"], width, label=\"Scratch F1\")\n",
    "    plt.bar(x + width*2, metrics_df[\"Agreement\"], width, label=\"Agreement\")\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Keras vs Scratch Model Comparison\")\n",
    "    plt.xticks(x, models)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../../output/results/rnn/model_comparison_fixed.png\")\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No results to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Debug Specific Models\n",
    "\n",
    "If you're still having issues with a specific model, let's debug it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Debugging 2_layer model ===\n",
      "\n",
      "\n",
      "Keras Model Layer Details:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer #  Layer Type           Input Shape          Output Shape         Config                        \n",
      "--------------------------------------------------------------------------------\n",
      "0        Embedding            N/A                  N/A                  in_dim=2836, out_dim=100      \n",
      "1        SimpleRNN            N/A                  N/A                  units=128, ret_seq=True       \n",
      "2        Dropout              N/A                  N/A                  rate=0.2                      \n",
      "3        SimpleRNN            N/A                  N/A                  units=64, ret_seq=False       \n",
      "4        Dropout              N/A                  N/A                  rate=0.2                      \n",
      "5        Dense                N/A                  N/A                  units=3, act=softmax          \n",
      "--------------------------------------------------------------------------------\n",
      "Processing layer 0: Embedding\n",
      "  Added Embedding layer: 2836 → 100\n",
      "Processing layer 1: SimpleRNN\n",
      "  Added RNN layer: 100 → 128 (return_sequences=True)\n",
      "Processing layer 2: Dropout\n",
      "  Added Dropout layer: rate=0.2\n",
      "Processing layer 3: SimpleRNN\n",
      "  Added RNN layer: 100 → 64 (return_sequences=False)\n",
      "Processing layer 4: Dropout\n",
      "  Added Dropout layer: rate=0.2\n",
      "Processing layer 5: Dense\n",
      "  Added Dense layer: 64 → 3\n",
      "  Added Softmax activation\n",
      "\n",
      "Scratch Model Layer Details:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer #  Layer Type           Input Dim       Output Dim      Other Details                 \n",
      "--------------------------------------------------------------------------------\n",
      "0        EmbeddingLayer       2836            100                                           \n",
      "1        RNNLayer             100             128             Bidirectional: False, RetSeq: True\n",
      "2        DropoutLayer         N/A             N/A             Rate: 0.2                     \n",
      "3        RNNLayer             100             64              Bidirectional: False, RetSeq: False\n",
      "4        DropoutLayer         N/A             N/A             Rate: 0.2                     \n",
      "5        DenseLayer           64              3                                             \n",
      "6        Softmax              N/A             N/A                                           \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Layer-by-Layer Comparison:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Layer #  Keras Type           Keras Config                   Scratch Type         Scratch Config                \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0        Embedding            in_dim=2836, out_dim=100       EmbeddingLayer       in_dim=2836, out_dim=100      \n",
      "1        SimpleRNN            units=128, ret_seq=True        RNNLayer             in_dim=100, hid_dim=128, bidir=False, ret_seq=True\n",
      "2        Dropout              rate=0.2                       DropoutLayer         rate=0.2                      \n",
      "3        SimpleRNN            units=64, ret_seq=False        RNNLayer             in_dim=100, hid_dim=64, bidir=False, ret_seq=False\n",
      "4        Dropout              rate=0.2                       DropoutLayer         rate=0.2                      \n",
      "5        Dense                units=3, act=softmax           DenseLayer           in_dim=64, out_dim=3          \n",
      "6        N/A                  N/A                            Softmax                                            \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Warning: Layer count mismatch: Custom model has 7 layers, Keras model has 6 layers\n",
      "Warning: No corresponding Keras layer for scratch layer 6\n",
      "Input shape: (5, 100)\n",
      "\n",
      "Keras model prediction process:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n",
      "Keras output shape: (5, 3)\n",
      "Keras raw output (first example):\n",
      "[0.00532407 0.01742935 0.97724664]\n",
      "Keras prediction: [2 1 0 2 1]\n",
      "\n",
      "Scratch model prediction process:\n",
      "Layer 0 input shape: (5, 100)\n",
      "Layer 1 input shape: (5, 100, 100)\n",
      "Layer 2 input shape: (5, 100, 128)\n",
      "Layer 3 input shape: (5, 100, 128)\n",
      "Warning: Input feature dimension 128 doesn't match expected dimension 100. This may cause issues.\n",
      "Layer 4 input shape: (5, 64)\n",
      "Layer 5 input shape: (5, 64)\n",
      "Layer 6 input shape: (5, 3)\n",
      "Model output shape: (5, 3)\n",
      "Scratch output shape: (5, 3)\n",
      "Scratch raw output (first example):\n",
      "[0.13401267 0.00421488 0.86177245]\n",
      "Scratch prediction: [2 1 0 0 1]\n",
      "\n",
      "Comparison:\n",
      "True labels: [2 1 0 2 1]\n",
      "Keras predictions: [2 1 0 2 1]\n",
      "Scratch predictions: [2 1 0 0 1]\n",
      "Agreement: 0.80\n",
      "\n",
      "Raw output difference (mean absolute diff): 0.187444\n",
      "Raw output difference (max absolute diff): 0.543055\n"
     ]
    }
   ],
   "source": [
    "def debug_model_predictions(keras_model, scratch_model, x_sample, y_sample):\n",
    "    \"\"\"Debug a small batch of predictions in detail\"\"\"\n",
    "    print(\"Input shape:\", x_sample.shape)\n",
    "    \n",
    "    # Process through Keras model\n",
    "    print(\"\\nKeras model prediction process:\")\n",
    "    keras_output = keras_model.predict(x_sample)\n",
    "    keras_preds = np.argmax(keras_output, axis=1)\n",
    "    print(\"Keras output shape:\", keras_output.shape)\n",
    "    print(\"Keras raw output (first example):\")\n",
    "    print(keras_output[0])\n",
    "    print(\"Keras prediction:\", keras_preds)\n",
    "    \n",
    "    # Process through scratch model with detailed logging\n",
    "    print(\"\\nScratch model prediction process:\")\n",
    "    try:\n",
    "        # This will use our RNNModel.forward which has shape printing\n",
    "        scratch_output = scratch_model.forward(x_sample)\n",
    "        scratch_preds = np.argmax(scratch_output, axis=1)\n",
    "        print(\"Scratch output shape:\", scratch_output.shape)\n",
    "        print(\"Scratch raw output (first example):\")\n",
    "        print(scratch_output[0])\n",
    "        print(\"Scratch prediction:\", scratch_preds)\n",
    "        \n",
    "        # Compare\n",
    "        print(\"\\nComparison:\")\n",
    "        print(f\"True labels: {y_sample}\")\n",
    "        print(f\"Keras predictions: {keras_preds}\")\n",
    "        print(f\"Scratch predictions: {scratch_preds}\")\n",
    "        print(f\"Agreement: {np.mean(keras_preds == scratch_preds):.2f}\")\n",
    "        \n",
    "        # Compare raw outputs\n",
    "        output_diff = np.abs(keras_output - scratch_output)\n",
    "        print(f\"\\nRaw output difference (mean absolute diff): {np.mean(output_diff):.6f}\")\n",
    "        print(f\"Raw output difference (max absolute diff): {np.max(output_diff):.6f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during scratch model forward pass: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Debug a specific model (e.g., 2-layer model)\n",
    "model_to_debug = \"2_layer\"\n",
    "\n",
    "if model_to_debug in model_paths:\n",
    "    print(f\"\\n=== Debugging {model_to_debug} model ===\\n\")\n",
    "    \n",
    "    # Load the Keras model\n",
    "    keras_model = load_model(model_paths[model_to_debug])\n",
    "    \n",
    "    # Build the scratch model and load weights\n",
    "    scratch_model = build_scratch_model_for_keras(keras_model)\n",
    "    scratch_model.load_weights_from_keras(keras_model)\n",
    "    \n",
    "    # Debug with a small batch of examples\n",
    "    sample_size = 5\n",
    "    x_sample = x_test[:sample_size]\n",
    "    y_sample = y_test[:sample_size]\n",
    "    \n",
    "    debug_model_predictions(keras_model, scratch_model, x_sample, y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Manual RNN Layer Check\n",
    "\n",
    "Let's test the RNN layer implementation directly to ensure it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RNN layer implementation...\n",
      "Input shape: (32, 100, 100)\n",
      "Output shape: (32, 64)\n",
      "Expected output shape: (32, 64)\n",
      "Output shape (return_sequences=True): (32, 100, 64)\n",
      "Expected output shape: (32, 100, 64)\n",
      "Output shape (bidirectional): (32, 128)\n",
      "Expected output shape: (32, 128)\n",
      "Output shape (bidirectional, return_sequences=True): (32, 100, 128)\n",
      "Expected output shape: (32, 100, 128)\n",
      "RNN layer tests completed.\n"
     ]
    }
   ],
   "source": [
    "def test_rnn_layer():\n",
    "    \"\"\"Test the RNN layer implementation directly\"\"\"\n",
    "    print(\"Testing RNN layer implementation...\")\n",
    "    \n",
    "    # Create a simple RNN layer\n",
    "    input_dim = 100\n",
    "    hidden_dim = 64\n",
    "    rnn = RNNLayer(input_dim=input_dim, hidden_dim=hidden_dim, return_sequences=False)\n",
    "    \n",
    "    # Create some random input data\n",
    "    batch_size = 32\n",
    "    seq_length = 100\n",
    "    inputs = np.random.randn(batch_size, seq_length, input_dim)\n",
    "    \n",
    "    # Forward pass\n",
    "    print(f\"Input shape: {inputs.shape}\")\n",
    "    output = rnn.forward(inputs)\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Expected output shape: ({batch_size}, {hidden_dim})\")\n",
    "    \n",
    "    # Test with return_sequences=True\n",
    "    rnn_seq = RNNLayer(input_dim=input_dim, hidden_dim=hidden_dim, return_sequences=True)\n",
    "    output_seq = rnn_seq.forward(inputs)\n",
    "    print(f\"Output shape (return_sequences=True): {output_seq.shape}\")\n",
    "    print(f\"Expected output shape: ({batch_size}, {seq_length}, {hidden_dim})\")\n",
    "    \n",
    "    # Test bidirectional\n",
    "    rnn_bidir = RNNLayer(input_dim=input_dim, hidden_dim=hidden_dim, bidirectional=True, return_sequences=False)\n",
    "    output_bidir = rnn_bidir.forward(inputs)\n",
    "    print(f\"Output shape (bidirectional): {output_bidir.shape}\")\n",
    "    print(f\"Expected output shape: ({batch_size}, {hidden_dim*2})\")\n",
    "    \n",
    "    # Test bidirectional with return_sequences\n",
    "    rnn_bidir_seq = RNNLayer(input_dim=input_dim, hidden_dim=hidden_dim, bidirectional=True, return_sequences=True)\n",
    "    output_bidir_seq = rnn_bidir_seq.forward(inputs)\n",
    "    print(f\"Output shape (bidirectional, return_sequences=True): {output_bidir_seq.shape}\")\n",
    "    print(f\"Expected output shape: ({batch_size}, {seq_length}, {hidden_dim*2})\")\n",
    "    \n",
    "    print(\"RNN layer tests completed.\")\n",
    "\n",
    "# Run the RNN layer test\n",
    "test_rnn_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this enhanced notebook, we've:\n",
    "\n",
    "1. Implemented a fixed RNN layer that properly supports multi-layer architectures\n",
    "2. Added detailed layer inspection to compare Keras and scratch models side by side\n",
    "3. Provided tools to debug specific issues in the model implementation\n",
    "4. Added direct testing of the RNN layer to verify its correctness\n",
    "\n",
    "The key enhancements over the previous version are:\n",
    "\n",
    "1. Side-by-side layer comparison to spot architecture mismatches\n",
    "2. Detailed shape tracking through each layer of the model\n",
    "3. Enhanced debugging tools to isolate specific issues\n",
    "4. Direct testing of the RNN layer implementation\n",
    "\n",
    "These changes should help identify and fix any remaining issues with the model implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
